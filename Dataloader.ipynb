{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import stft\n",
    "\n",
    "import librosa\n",
    "import cv2\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from superlets import wavelet_transform, adaptive_superlet_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, USE_WAVELET='db16',root = '..',specMethod = 'mel'):\n",
    "        '''\n",
    "        csv_path: path to your metadata\n",
    "        \\n\n",
    "        USE_WAVELET:\n",
    "        \\n\n",
    "        \\t'LPF10'-> for low pass with 10 Hz \\n\n",
    "        \\t'LPF20'-> for low pass with 20 Hz \\n\n",
    "        \\t'USE_WAVELET'-> use other default wavelets \\n\n",
    "        root: path to 'hms-harmful-brain-activity-classification'\n",
    "        specMethod: 'mel', 'SL','CWT'\n",
    "        '''\n",
    "\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.USE_WAVELET = USE_WAVELET\n",
    "\n",
    "        self.root = root\n",
    "        self.specMethod = specMethod\n",
    "\n",
    "        self.NAMES = ['LL','LP','RP','RR']\n",
    "\n",
    "        self.FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "                ['Fp1','F3','C3','P3','O1'],\n",
    "                ['Fp2','F8','T4','T6','O2'],\n",
    "                ['Fp2','F4','C4','P4','O2']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        retSpecs,consensus, labels, offset, eeg_id = self.spectrogram_from_eeg(idx)\n",
    "\n",
    "        if self.transform:\n",
    "            retSpecs = self.transform(retSpecs)\n",
    "\n",
    "        return retSpecs, labels, offset, eeg_id\n",
    "    \n",
    "    def spectrogram_from_eeg(self,eeg_id, display=False):\n",
    "    \n",
    "\n",
    "        sliced_eegs,consensus, labels, offset, eeg_id = self.getWindowsfromEEG(eeg_id)\n",
    "        eeg = sliced_eegs[0]\n",
    "        \n",
    "        \n",
    "        if display: plt.figure(figsize=(10,7))\n",
    "\n",
    "        retSpecs = []\n",
    "        retEEGs = []\n",
    "        ogEEGs = []\n",
    "\n",
    "        img = np.zeros((128,128),dtype='float32')\n",
    "        signals = []\n",
    "        signalsX = []\n",
    "        signalsXOG = []\n",
    "        for k in range(4):\n",
    "            COLS = self.FEATS[k]\n",
    "\n",
    "            tempSpec= np.zeros((128,128))\n",
    "\n",
    "            if self.USE_WAVELET==\"LPF10\" or self.USE_WAVELET==\"LPF20\" or self.USE_WAVELET == \"None\":\n",
    "                temp = np.zeros((2001))\n",
    "                tempOG = np.zeros((2001))\n",
    "            else:\n",
    "                temp = np.zeros((2002))\n",
    "                tempOG = np.zeros((2001))\n",
    "            \n",
    "            for kk in range(4):\n",
    "            \n",
    "        \n",
    "                x = eeg[COLS[kk]] - eeg[COLS[kk+1]]\n",
    "                tempOG+=x\n",
    "        \n",
    "                m = np.nanmean(x)\n",
    "                if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "                else: x[:] = 0\n",
    "\n",
    "                \n",
    "                if self.USE_WAVELET=='LPF10':\n",
    "            \n",
    "                    x = self.apply_lpf(x,cutoff_freq=10)\n",
    "                elif self.USE_WAVELET=='LPF20':\n",
    "            \n",
    "                    x = self.apply_lpf(x,cutoff_freq=20)\n",
    "                else:\n",
    "                    x = self.denoise(x, wavelet=self.USE_WAVELET)\n",
    "\n",
    "                temp+=x\n",
    "                signals.append(x)\n",
    "                \n",
    "\n",
    "                # MEL SPEC, STFT, CWT and Superlets\n",
    "\n",
    "                if self.specMethod == 'MEL':\n",
    "\n",
    "                    mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//128, \n",
    "                        n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n",
    "\n",
    "            \n",
    "                    width = (mel_spec.shape[1]//32)*32\n",
    "                    \n",
    "                    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "\n",
    "            \n",
    "                    mel_spec_db = (mel_spec_db+40)/40 \n",
    "\n",
    "                    tempSpec += mel_spec_db\n",
    "\n",
    "                if self.specMethod == 'SL':\n",
    "                    # print('OK')\n",
    "                    \n",
    "                    freqs = jnp.linspace(1, 25, 25)\n",
    "\n",
    "                    scalogram = adaptive_superlet_transform(x, freqs, sampling_freq=200, \n",
    "                                            base_cycle=5, min_order=5, \n",
    "                                            max_order=30, mode=\"add\")\n",
    "                    \n",
    "                    image = np.abs(scalogram)**2\n",
    "                    image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                    image_to_show = np.uint8(image_normalized)\n",
    "\n",
    "                    \n",
    "                    # image_colored = cv2.applyColorMap(image_to_show, cv2.COLORMAP_JET)\n",
    "\n",
    "                    # window_name = f\"Base cycles: {base_cycle}, Orders: {min_order}-{max_order}\"\n",
    "                    # cv2.imwrite(f'superlet-{i}.png',image_to_show)\n",
    "                    tempSpec += cv2.resize(image_to_show, (128, 128))\n",
    "\n",
    "\n",
    "\n",
    "                if self.specMethod == 'CWT':\n",
    "\n",
    "                    def spectrogram_cwt(signal, wavelet='morl', scales=np.arange(1, 128)):\n",
    "                        coeffs, freqs = pywt.cwt(signal, scales, wavelet)\n",
    "                        power = (np.abs(coeffs)) ** 2\n",
    "                        return power, freqs\n",
    "\n",
    "\n",
    "                    fs = 200\n",
    "                    t = np.arange(0, 10, 1/fs)\n",
    "                    \n",
    "\n",
    "                    scales = np.arange(1, 32)\n",
    "\n",
    "\n",
    "                    power, freqs = spectrogram_cwt(x, scales=scales)\n",
    "\n",
    "\n",
    "                    power_normalized = ((power - power.min()) / (power.max() - power.min()) * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "                    spectrogram_image_resized = cv2.resize(power_normalized, (128, 128))\n",
    "\n",
    "                    tempSpec += spectrogram_image_resized\n",
    "\n",
    "                \n",
    "            temp/=4.0\n",
    "            tempOG/=4.0\n",
    "            \n",
    "            signalsX.append(temp)    \n",
    "            signalsXOG.append(tempOG)\n",
    "\n",
    "\n",
    "            tempSpec /= 4.0\n",
    "\n",
    "            img  = np.vstack((img,tempSpec))\n",
    "\n",
    "\n",
    "        retSpecs.append(img[128:])\n",
    "\n",
    "        retEEGs.append(np.array(signalsX))\n",
    "        ogEEGs.append(np.array(signalsXOG))\n",
    "\n",
    "\n",
    "        return np.array(retSpecs[0]), consensus, labels, offset, eeg_id\n",
    "\n",
    "    def getWindowsfromEEG(self,loc):\n",
    "\n",
    "        labelMap = {'Seizure':0,'GPD':1,'LRDA':2,'Other':3,'GRDA':4,'LPD':5}\n",
    "\n",
    "        subSet = self.metadata.iloc[loc]\n",
    "        eeg_id = subSet['eeg_id']\n",
    "\n",
    "        labels = np.array([int(subSet['seizure_vote']), int(subSet['lpd_vote']) , int(subSet['gpd_vote'])\n",
    "                        ,int(subSet['lrda_vote']), int(subSet['grda_vote']), int(subSet['other_vote'])])\n",
    "\n",
    "        consensus = labelMap[subSet['expert_consensus']]\n",
    "\n",
    "        eeg = pd.read_parquet(f'{self.root}/train_eegs/{eeg_id}.parquet')\n",
    "\n",
    "        fs = 200\n",
    "        eeg[\"time\"] = eeg.index / fs\n",
    "        eeg.set_index(\"time\", inplace=True)\n",
    "        eeg.index\n",
    "\n",
    "        offSet = int(subSet['eeg_label_offset_seconds'])\n",
    "\n",
    "        toRet = []\n",
    "\n",
    "        toRet.append(eeg.loc[offSet+20:offSet+30])\n",
    "\n",
    "        return toRet,np.array(consensus), np.array(labels),np.array(offSet),np.array(eeg_id)\n",
    "\n",
    "    def apply_lpf(self,data, sampling_rate=200, cutoff_freq=10, order=5):\n",
    "\n",
    "        nyquist_freq = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist_freq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = filtfilt(b, a, data)\n",
    "\n",
    "        return filtered_data\n",
    "\n",
    "    def maddest(self,d, axis=None):\n",
    "        return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "    def denoise(self,x, wavelet='haar', level=1):    \n",
    "        coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "        sigma = (1/0.6745) * self.maddest(coeff[-level])\n",
    "\n",
    "        uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "        coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "\n",
    "        ret=pywt.waverec(coeff, wavelet, mode='per')\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "specMethods = ['MEL','CWT','SL']\n",
    "filteringMethods = ['LPF10','LPF20','db8','coif16','haar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_path = 'hms-harmful-brain-activity-classification/train_mine.csv'\n",
    "test_path = 'hms-harmful-brain-activity-classification/test_mine.csv'\n",
    "val_path = 'hms-harmful-brain-activity-classification/val_mine.csv'\n",
    "root = 'hms-harmful-brain-activity-classification'\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(csv_path=train_path, transform=transform,root=root,USE_WAVELET=filteringMethods[i],specMethod=specMethods[j])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(csv_path=test_path, transform=transform,root=root,USE_WAVELET=filteringMethods[i],specMethod=specMethods[j])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = CustomDataset(csv_path=val_path, transform=transform,root=root,USE_WAVELET=filteringMethods[i],specMethod=specMethods[j])\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataPath = f'hms-harmful-brain-activity-classification-{filteringMethods[i]}-{specMethods[j]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(newDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(newDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('train')\n",
    "os.mkdir('test')\n",
    "os.mkdir('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Processed Specs for train...\n",
      "85440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 179/85440 [00:33<4:22:00,  5.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaving Processed Specs for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loaderDict[i]))\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m specs,labels, offset, eeg_id \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28miter\u001b[39m(loaderDict[i])):\n\u001b[1;32m      9\u001b[0m     img,label,offset,eeg_id \u001b[38;5;241m=\u001b[39m specs\u001b[38;5;241m.\u001b[39msqueeze(),labels\u001b[38;5;241m.\u001b[39msqueeze(), offset\u001b[38;5;241m.\u001b[39msqueeze(), eeg_id\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimsave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewDataPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meeg_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m,img\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[44], line 36\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 36\u001b[0m     retSpecs,consensus, labels, offset, eeg_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectrogram_from_eeg\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     39\u001b[0m         retSpecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(retSpecs)\n",
      "Cell \u001b[0;32mIn[44], line 102\u001b[0m, in \u001b[0;36mCustomDataset.spectrogram_from_eeg\u001b[0;34m(self, eeg_id, display)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# MEL SPEC, STFT, CWT and Superlets\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecMethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEL\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 102\u001b[0m     mel_spec \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     width \u001b[38;5;241m=\u001b[39m (mel_spec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[1;32m    108\u001b[0m     mel_spec_db \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mpower_to_db(mel_spec, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)[:,:width]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/librosa/feature/spectral.py:2145\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m   2143\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2145\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m...ft,mf->...mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_basis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/numpy/core/einsumfunc.py:1419\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     right_pos\u001b[38;5;241m.\u001b[39mappend(input_right\u001b[38;5;241m.\u001b[39mfind(s))\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# Contract!\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m new_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtmp_operands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mright_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# Build a new view if needed\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tensor_result \u001b[38;5;241m!=\u001b[39m results_index) \u001b[38;5;129;01mor\u001b[39;00m handle_out:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/numpy/core/numeric.py:1139\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1137\u001b[0m at \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose(newaxes_a)\u001b[38;5;241m.\u001b[39mreshape(newshape_a)\n\u001b[1;32m   1138\u001b[0m bt \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mtranspose(newaxes_b)\u001b[38;5;241m.\u001b[39mreshape(newshape_b)\n\u001b[0;32m-> 1139\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreshape(olda \u001b[38;5;241m+\u001b[39m oldb)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataSubsets = ['train','test','val']\n",
    "loaderDict = {'train':train_loader,'test':test_loader,'val':val_loader}\n",
    "for i in dataSubsets:\n",
    "    print(f'Saving Processed Specs for {i}...')\n",
    "    print(len(loaderDict[i]))\n",
    "\n",
    "    for specs,labels, offset, eeg_id in tqdm(iter(loaderDict[i])):\n",
    "\n",
    "        img,label,offset,eeg_id = specs.squeeze(),labels.squeeze(), offset.squeeze(), eeg_id.squeeze()\n",
    "\n",
    "        plt.imsave(f'{newDataPath}/{i}/{eeg_id}-{offset}.png',img.cpu().numpy())\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
