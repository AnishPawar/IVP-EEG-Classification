{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import stft\n",
    "\n",
    "import librosa\n",
    "import cv2\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from superlets import wavelet_transform, adaptive_superlet_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wavelet functions we can use:\n",
      "['bior1.1', 'bior1.3', 'bior1.5', 'bior2.2', 'bior2.4', 'bior2.6', 'bior2.8', 'bior3.1', 'bior3.3', 'bior3.5', 'bior3.7', 'bior3.9', 'bior4.4', 'bior5.5', 'bior6.8', 'cgau1', 'cgau2', 'cgau3', 'cgau4', 'cgau5', 'cgau6', 'cgau7', 'cgau8', 'cmor', 'coif1', 'coif2', 'coif3', 'coif4', 'coif5', 'coif6', 'coif7', 'coif8', 'coif9', 'coif10', 'coif11', 'coif12', 'coif13', 'coif14', 'coif15', 'coif16', 'coif17', 'db1', 'db2', 'db3', 'db4', 'db5', 'db6', 'db7', 'db8', 'db9', 'db10', 'db11', 'db12', 'db13', 'db14', 'db15', 'db16', 'db17', 'db18', 'db19', 'db20', 'db21', 'db22', 'db23', 'db24', 'db25', 'db26', 'db27', 'db28', 'db29', 'db30', 'db31', 'db32', 'db33', 'db34', 'db35', 'db36', 'db37', 'db38', 'dmey', 'fbsp', 'gaus1', 'gaus2', 'gaus3', 'gaus4', 'gaus5', 'gaus6', 'gaus7', 'gaus8', 'haar', 'mexh', 'morl', 'rbio1.1', 'rbio1.3', 'rbio1.5', 'rbio2.2', 'rbio2.4', 'rbio2.6', 'rbio2.8', 'rbio3.1', 'rbio3.3', 'rbio3.5', 'rbio3.7', 'rbio3.9', 'rbio4.4', 'rbio5.5', 'rbio6.8', 'shan', 'sym2', 'sym3', 'sym4', 'sym5', 'sym6', 'sym7', 'sym8', 'sym9', 'sym10', 'sym11', 'sym12', 'sym13', 'sym14', 'sym15', 'sym16', 'sym17', 'sym18', 'sym19', 'sym20']\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "print(\"The wavelet functions we can use:\")\n",
    "print(pywt.wavelist())\n",
    "\n",
    "USE_WAVELET = \"None\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, USE_WAVELET='db16',root = '..',specMethod = 'mel'):\n",
    "        '''\n",
    "        csv_path: path to your metadata\n",
    "        \\n\n",
    "        USE_WAVELET:\n",
    "        \\n\n",
    "        \\t'LPF10'-> for low pass with 10 Hz \\n\n",
    "        \\t'LPF20'-> for low pass with 20 Hz \\n\n",
    "        \\t'USE_WAVELET'-> use other default wavelets \\n\n",
    "        root: path to 'hms-harmful-brain-activity-classification'\n",
    "        specMethod: 'mel', 'SL','CWT'\n",
    "        '''\n",
    "\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.USE_WAVELET = USE_WAVELET\n",
    "\n",
    "        self.root = root\n",
    "        self.specMethod = specMethod\n",
    "\n",
    "        self.NAMES = ['LL','LP','RP','RR']\n",
    "\n",
    "        self.FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "                ['Fp1','F3','C3','P3','O1'],\n",
    "                ['Fp2','F8','T4','T6','O2'],\n",
    "                ['Fp2','F4','C4','P4','O2']]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        retSpecs,consensus, labels, offset, eeg_id = self.spectrogram_from_eeg(idx)\n",
    "\n",
    "        if self.transform:\n",
    "            retSpecs = self.transform(retSpecs)\n",
    "\n",
    "        return retSpecs, labels, offset, eeg_id\n",
    "    \n",
    "\n",
    "\n",
    "    def spectrogram_from_eeg(self,eeg_id, display=False):\n",
    "    \n",
    "\n",
    "        sliced_eegs,consensus, labels, offset, eeg_id = self.getWindowsfromEEG(eeg_id)\n",
    "        eeg = sliced_eegs[0]\n",
    "        \n",
    "        \n",
    "        if display: plt.figure(figsize=(10,7))\n",
    "\n",
    "        retSpecs = []\n",
    "        retEEGs = []\n",
    "        ogEEGs = []\n",
    "\n",
    "        img = np.zeros((128,128),dtype='float32')\n",
    "        signals = []\n",
    "        signalsX = []\n",
    "        signalsXOG = []\n",
    "        for k in range(4):\n",
    "            COLS = self.FEATS[k]\n",
    "\n",
    "            tempSpec= np.zeros((128,128))\n",
    "\n",
    "            if self.USE_WAVELET==\"LPF10\" or self.USE_WAVELET==\"LPF20\" or self.USE_WAVELET == \"None\":\n",
    "                temp = np.zeros((2001))\n",
    "                tempOG = np.zeros((2001))\n",
    "            else:\n",
    "                temp = np.zeros((2002))\n",
    "                tempOG = np.zeros((2001))\n",
    "            \n",
    "            for kk in range(4):\n",
    "            \n",
    "        \n",
    "                x = eeg[COLS[kk]] - eeg[COLS[kk+1]]\n",
    "                tempOG+=x\n",
    "        \n",
    "                m = np.nanmean(x)\n",
    "                if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "                else: x[:] = 0\n",
    "\n",
    "                \n",
    "                if self.USE_WAVELET=='LPF10':\n",
    "            \n",
    "                    x = self.apply_lpf(x,cutoff_freq=10)\n",
    "                elif self.USE_WAVELET=='LPF20':\n",
    "            \n",
    "                    x = self.apply_lpf(x,cutoff_freq=20)\n",
    "                else:\n",
    "                    x = self.denoise(x, wavelet=self.USE_WAVELET)\n",
    "\n",
    "                temp+=x\n",
    "                signals.append(x)\n",
    "                \n",
    "\n",
    "                # MEL SPEC, STFT, CWT and Superlets\n",
    "\n",
    "                if self.specMethod == 'MEL':\n",
    "\n",
    "                    mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//128, \n",
    "                        n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n",
    "\n",
    "            \n",
    "                    width = (mel_spec.shape[1]//32)*32\n",
    "                    \n",
    "                    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "\n",
    "            \n",
    "                    mel_spec_db = (mel_spec_db+40)/40 \n",
    "\n",
    "                    tempSpec += mel_spec_db\n",
    "\n",
    "                if self.specMethod == 'SL':\n",
    "                    # print('OK')\n",
    "                    \n",
    "                    freqs = jnp.linspace(1, 25, 25)\n",
    "\n",
    "                    scalogram = adaptive_superlet_transform(x, freqs, sampling_freq=200, \n",
    "                                            base_cycle=5, min_order=5, \n",
    "                                            max_order=30, mode=\"add\")\n",
    "                    \n",
    "                    image = np.abs(scalogram)**2\n",
    "                    image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                    image_to_show = np.uint8(image_normalized)\n",
    "\n",
    "                    \n",
    "                    # image_colored = cv2.applyColorMap(image_to_show, cv2.COLORMAP_JET)\n",
    "\n",
    "                    # window_name = f\"Base cycles: {base_cycle}, Orders: {min_order}-{max_order}\"\n",
    "                    # cv2.imwrite(f'superlet-{i}.png',image_to_show)\n",
    "                    tempSpec += cv2.resize(image_to_show, (128, 128))\n",
    "\n",
    "\n",
    "\n",
    "                if self.specMethod == 'CWT':\n",
    "\n",
    "                    def spectrogram_cwt(signal, wavelet='morl', scales=np.arange(1, 128)):\n",
    "                        coeffs, freqs = pywt.cwt(signal, scales, wavelet)\n",
    "                        power = (np.abs(coeffs)) ** 2\n",
    "                        return power, freqs\n",
    "\n",
    "\n",
    "                    fs = 200\n",
    "                    t = np.arange(0, 10, 1/fs)\n",
    "                    \n",
    "\n",
    "                    scales = np.arange(1, 32)\n",
    "\n",
    "\n",
    "                    power, freqs = spectrogram_cwt(x, scales=scales)\n",
    "\n",
    "\n",
    "                    power_normalized = ((power - power.min()) / (power.max() - power.min()) * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "                    spectrogram_image_resized = cv2.resize(power_normalized, (128, 128))\n",
    "\n",
    "                    tempSpec += spectrogram_image_resized\n",
    "\n",
    "                \n",
    "            temp/=4.0\n",
    "            tempOG/=4.0\n",
    "            \n",
    "            signalsX.append(temp)    \n",
    "            signalsXOG.append(tempOG)\n",
    "\n",
    "\n",
    "            tempSpec /= 4.0\n",
    "\n",
    "            img  = np.vstack((img,tempSpec))\n",
    "\n",
    "\n",
    "        retSpecs.append(img[128:])\n",
    "\n",
    "        retEEGs.append(np.array(signalsX))\n",
    "        ogEEGs.append(np.array(signalsXOG))\n",
    "\n",
    "\n",
    "        return np.array(retSpecs[0]), consensus, labels, offset, eeg_id\n",
    "\n",
    "    def getWindowsfromEEG(self,loc):\n",
    "\n",
    "        labelMap = {'Seizure':0,'GPD':1,'LRDA':2,'Other':3,'GRDA':4,'LPD':5}\n",
    "\n",
    "        subSet = self.metadata.iloc[loc]\n",
    "        eeg_id = subSet['eeg_id']\n",
    "\n",
    "        labels = np.array([int(subSet['seizure_vote']), int(subSet['lpd_vote']) , int(subSet['gpd_vote'])\n",
    "                        ,int(subSet['lrda_vote']), int(subSet['grda_vote']), int(subSet['other_vote'])])\n",
    "\n",
    "        consensus = labelMap[subSet['expert_consensus']]\n",
    "\n",
    "        eeg = pd.read_parquet(f'{self.root}/train_eegs/{eeg_id}.parquet')\n",
    "\n",
    "        fs = 200\n",
    "        eeg[\"time\"] = eeg.index / fs\n",
    "        eeg.set_index(\"time\", inplace=True)\n",
    "        eeg.index\n",
    "\n",
    "        offSet = int(subSet['eeg_label_offset_seconds'])\n",
    "\n",
    "        toRet = []\n",
    "\n",
    "        toRet.append(eeg.loc[offSet+20:offSet+30])\n",
    "\n",
    "        return toRet,np.array(consensus), np.array(labels),np.array(offSet),np.array(eeg_id)\n",
    "\n",
    "    def apply_lpf(self,data, sampling_rate=200, cutoff_freq=10, order=5):\n",
    "\n",
    "        nyquist_freq = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist_freq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = filtfilt(b, a, data)\n",
    "\n",
    "        return filtered_data\n",
    "\n",
    "    def maddest(self,d, axis=None):\n",
    "        return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "    def denoise(self,x, wavelet='haar', level=1):    \n",
    "        coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "        sigma = (1/0.6745) * self.maddest(coeff[-level])\n",
    "\n",
    "        uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "        coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "\n",
    "        ret=pywt.waverec(coeff, wavelet, mode='per')\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "specMethods = ['MEL','CWT','SL']\n",
    "filteringMethods = ['LPF10','LPF20','db8','db16','coif16','haar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512,512))\n",
    "])\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_path = 'hms-harmful-brain-activity-classification/train_mine.csv'\n",
    "test_path = 'hms-harmful-brain-activity-classification/test_mine.csv'\n",
    "val_path = 'hms-harmful-brain-activity-classification/val_mine.csv'\n",
    "root = 'hms-harmful-brain-activity-classification'\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(csv_path=train_path, transform=transform,root=root,USE_WAVELET=filteringMethods[i],specMethod=specMethods[j])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(csv_path=test_path, transform=transform,root=root,USE_WAVELET=filteringMethods[i],specMethod=specMethods[j])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = CustomDataset(csv_path=val_path, transform=transform,root=root,USE_WAVELET=filteringMethods[i],specMethod=specMethods[j])\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataPath = f'hms-harmful-brain-activity-classification-{filteringMethods[i]}-{specMethods[j]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(newDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(newDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('train')\n",
    "os.mkdir('test')\n",
    "os.mkdir('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '/Users/anishpawar/MTech/Sem-2/IVP/Project_PreProc_Final_Report/IVP-EEG-Classification/'\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDatasetType = 'val'\n",
    "\n",
    "\n",
    "loaderDict = {'train':train_loader,'test':test_loader,'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10680\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/PIL/ImageFile.py:536\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[1;32m    537\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m specs,labels, offset, eeg_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(loaderDict[saveDatasetType]):\n\u001b[1;32m      5\u001b[0m     img,label,offset,eeg_id \u001b[38;5;241m=\u001b[39m specs\u001b[38;5;241m.\u001b[39msqueeze(),labels\u001b[38;5;241m.\u001b[39msqueeze(), offset\u001b[38;5;241m.\u001b[39msqueeze(), eeg_id\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnewDataPath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msaveDatasetType\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43meeg_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moffset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print( )\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/matplotlib/pyplot.py:2200\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave)\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimsave\u001b[39m(fname, arr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/matplotlib/image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/PIL/Image.py:2439\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2436\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2439\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2440\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/PIL/PngImagePlugin.py:1402\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1398\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[1;32m   1399\u001b[0m         im, fp, chunk, rawmode, default_image, append_images\n\u001b[1;32m   1400\u001b[0m     )\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/PIL/ImageFile.py:540\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    538\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 540\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    542\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ivp/lib/python3.8/site-packages/PIL/ImageFile.py:559\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    560\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(len(loaderDict[saveDatasetType]))\n",
    "\n",
    "for specs,labels, offset, eeg_id in iter(loaderDict[saveDatasetType]):\n",
    "\n",
    "    img,label,offset,eeg_id = specs.squeeze(),labels.squeeze(), offset.squeeze(), eeg_id.squeeze()\n",
    "\n",
    "    plt.imsave(f'{newDataPath}/{saveDatasetType}/{eeg_id}-{offset}.png',img.cpu().numpy())\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
