{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8176205,"sourceType":"datasetVersion","datasetId":4839831},{"sourceId":8176439,"sourceType":"datasetVersion","datasetId":4840001},{"sourceId":8196662,"sourceType":"datasetVersion","datasetId":4855160},{"sourceId":8232030,"sourceType":"datasetVersion","datasetId":4882002},{"sourceId":8232162,"sourceType":"datasetVersion","datasetId":4882096},{"sourceId":8233045,"sourceType":"datasetVersion","datasetId":4882714},{"sourceId":8234069,"sourceType":"datasetVersion","datasetId":4883507},{"sourceId":8234114,"sourceType":"datasetVersion","datasetId":4883547}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nimport timm\nimport gc\n\nfrom fastai.vision.all import *\nfrom fastcore.parallel import *","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-04-26T02:48:12.910177Z","iopub.execute_input":"2024-04-26T02:48:12.910550Z","iopub.status.idle":"2024-04-26T02:48:12.918076Z","shell.execute_reply.started":"2024-04-26T02:48:12.910498Z","shell.execute_reply":"2024-04-26T02:48:12.916557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom scipy.signal import butter, filtfilt\nimport librosa\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom tqdm import tqdm,trange,tqdm_notebook\nfrom multiprocessing import Pool\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:48:12.922465Z","iopub.execute_input":"2024-04-26T02:48:12.928065Z","iopub.status.idle":"2024-04-26T02:48:12.938303Z","shell.execute_reply.started":"2024-04-26T02:48:12.928013Z","shell.execute_reply":"2024-04-26T02:48:12.934555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Fine Tuned`DataLoaders`","metadata":{}},{"cell_type":"markdown","source":"Instead of processing the parquet files, I'm now using images directly which I have saved here after preprocessing and converting into the spectrogram. ","metadata":{}},{"cell_type":"code","source":"class Upload_Dataset(Dataset):\n    def __init__(self, csv_path, transform=None, root=\"..\", min_total_labels=10):\n        self.metadata = pd.read_csv(csv_path)\n        self.root = root\n        self.transform = transform\n        self.label_map = {'Seizure': 0, 'GPD': 1, 'LRDA': 2, 'Other': 3, 'GRDA': 4, 'LPD': 5}\n        self.min_total_labels = min_total_labels\n\n        # Filter metadata based on minimum total labels\n        self.metadata = self.metadata[self.metadata[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1) >= self.min_total_labels]\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, idx):\n        subSet = self.metadata.iloc[idx]\n        eeg_id = subSet['eeg_id']\n        offset_seconds = int(subSet['eeg_label_offset_seconds'])\n        image_name = f\"{eeg_id}-{offset_seconds}.png\"\n        image_path = os.path.join(self.root, image_name)\n        image = Image.open(image_path)\n\n        image = self.transform(image)\n\n        # Extract labels\n        labels = np.array([subSet['seizure_vote'], subSet['lpd_vote'], subSet['gpd_vote'],\n                           subSet['lrda_vote'], subSet['grda_vote'], subSet['other_vote']], dtype=float)\n        total_labels = np.sum(labels)\n        labels /= total_labels\n\n        # Extract consensus\n        consensus = self.label_map[subSet['expert_consensus']]\n\n        return image, labels, consensus","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:48:12.939905Z","iopub.execute_input":"2024-04-26T02:48:12.940582Z","iopub.status.idle":"2024-04-26T02:48:12.953842Z","shell.execute_reply.started":"2024-04-26T02:48:12.940545Z","shell.execute_reply":"2024-04-26T02:48:12.952344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\nbatch_size = 64\n\ntrain_path = '/kaggle/input/hms-datasplit/train_mine.csv'\ntest_path = '/kaggle/input/hms-datasplit/test_mine.csv'\nval_path = '/kaggle/input/hms-datasplit/val_mine.csv'\nroot = '/kaggle/input/hms-superlets'\nfilter_method = 'db8' # Here we can change it to LPF10, LPF20 and db8 also\ntransform_method = 'SL' # Here we can change the tranform method to Superlet(SL) and MEL also.\npre_spec = os.path.join(root, f\"/kaggle/input/hms-superlets/hms-harmful-brain-activity-classification-{filter_method}-{transform_method}/hms-harmful-brain-activity-classification-{filter_method}-{transform_method}\")\n\ntrain_dataset = Upload_Dataset(csv_path=train_path, transform=transform,root=os.path.join(pre_spec,f\"train\"))\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n\n\ntest_dataset = Upload_Dataset(csv_path=test_path, transform=transform,root=os.path.join(pre_spec,f\"test\"))\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n\n\nval_dataset = Upload_Dataset(csv_path=val_path, transform=transform,root=os.path.join(pre_spec,f\"val\"))\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:48:12.955502Z","iopub.execute_input":"2024-04-26T02:48:12.956464Z","iopub.status.idle":"2024-04-26T02:48:13.203300Z","shell.execute_reply.started":"2024-04-26T02:48:12.956435Z","shell.execute_reply":"2024-04-26T02:48:13.202378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Pre-trained Weights and Fine tune","metadata":{}},{"cell_type":"markdown","source":"Here we have tried out 4 different Models which we have loaded using timm such as ConvNextv2_atto, EfficientNet, Swinv2_tiny and MaxViT. Similarly try out the models also with different methods and variantions in parameters on already pretrained weights and fine tune it...","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport timm\ncheckpoint = torch.load(\"/kaggle/input/maxvit-tiny/2024-04-24 15_03_43.110590-db8-SL-0.6307523211319289.pt\")\n\nclass ConvNext(nn.Module):\n    def __init__(self, n_classes, num_input_channels=1, pretrained=False):\n        super(ConvNext, self).__init__()\n\n        self.model = timm.create_model(\"maxvit_tiny_tf_224.in1k\", pretrained=False, in_chans=num_input_channels, num_classes=n_classes)\n        if pretrained:\n            state_dict = {k.replace('module.model.', ''): v for k, v in checkpoint['model_state_dict'].items()}\n            self.model.load_state_dict(state_dict)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nepoch = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n    convnext_model = nn.DataParallel(ConvNext(6, 1, True)).to(device)\nelse:\n    convnext_model = ConvNext(6, 1, True).to(device)\n\noptimizer = torch.optim.Adam(convnext_model.parameters(), lr=1e-04)\n\nloss_history = [[], []]\naccuracy_history = [[], []]\nacc_epoch_history = [[],[]]\nloss_epoch_history = [[],[]]","metadata":{"execution":{"iopub.status.busy":"2024-04-26T01:46:01.128302Z","iopub.execute_input":"2024-04-26T01:46:01.128623Z","iopub.status.idle":"2024-04-26T01:46:04.859684Z","shell.execute_reply.started":"2024-04-26T01:46:01.128596Z","shell.execute_reply":"2024-04-26T01:46:04.858783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training and Evaluation on Fine-tuned data","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\ncurrent_dateTime = datetime.now()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T01:46:04.860847Z","iopub.execute_input":"2024-04-26T01:46:04.861168Z","iopub.status.idle":"2024-04-26T01:46:04.866246Z","shell.execute_reply.started":"2024-04-26T01:46:04.861143Z","shell.execute_reply":"2024-04-26T01:46:04.864795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\nprecision_history = [[], []]\nrecall_history = [[], []]\nf1_history = [[], []]\n\nfor e in trange(epoch):\n    convnext_model.train()\n    print(f\"====================== EPOCH {e+1} ======================\")\n    print(\"Training.....\")\n    for i, (data, labels, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        data, labels, target = data.to(device), labels.to(device), target.to(device)\n        output = convnext_model(data.float())\n        labels = labels.float()\n        loss = F.kl_div(F.log_softmax(output, dim=1), labels, reduction='batchmean')\n        \n        loss.backward()\n        \n        nn.utils.clip_grad_norm_(convnext_model.parameters(), 3)\n\n        loss_history[0].append(loss.item())\n        \n        accuracy = (output.argmax(dim=1) == target).float().mean()\n        \n        accuracy_history[0].append(accuracy)\n        \n        optimizer.step()\n        \n        if(i%50 == 0):\n            print(f\"MINIBATCH {i+1}/{len(train_loader)} TRAIN LOSS : {loss_history[0][-1]}\")\n    \n    print(\"Validation.....\")\n    convnext_model.eval()\n    \n    with torch.no_grad():\n        true_positives = 0\n        false_positives = 0\n        false_negatives = 0\n        for i, (data, labels, target) in enumerate(val_loader):\n            data, labels, target = data.to(device), labels.to(device), target.to(device)\n            output = convnext_model(data)\n            labels = labels.float()\n            loss = F.kl_div(F.log_softmax(output, dim=1), labels, reduction='batchmean')\n            \n            predicted_labels = output.argmax(dim=1)\n            true_positives += ((predicted_labels == target) & (predicted_labels == 1)).sum().item()\n            false_positives += ((predicted_labels == 1) & (target == 0)).sum().item()\n            false_negatives += ((predicted_labels == 0) & (target == 1)).sum().item()\n\n            accuracy = (output.argmax(dim=1) == target).float().mean()\n            loss_history[1].append(loss.item())\n            accuracy_history[1].append(accuracy)\n        \n        precision = precision_score(target.cpu(), predicted_labels.cpu(), average='weighted', zero_division=1)\n        recall = recall_score(target.cpu(), predicted_labels.cpu(), average='weighted', zero_division=1)\n        f1 = f1_score(target.cpu(), predicted_labels.cpu(), average='weighted', zero_division=1)\n\n        precision_history[1].append(precision)\n        recall_history[1].append(recall)\n        f1_history[1].append(f1)\n        \n    acc_epoch_history[0].append(sum(accuracy_history[0][-1:-len(train_loader):-1])/len(train_loader))\n    acc_epoch_history[1].append(sum(accuracy_history[1][-1:-len(val_loader):-1])/len(val_loader))\n    \n    loss_epoch_history[0].append(sum(loss_history[0][-1:-len(train_loader):-1])/len(train_loader))\n    loss_epoch_history[1].append(sum(loss_history[1][-1:-len(val_loader):-1])/len(val_loader))\n    \n    print(\"====================================================\")\n    print(f\"TRAIN ACC : {acc_epoch_history[0][-1]}  TRAIN LOSS : {loss_epoch_history[0][-1]}\")\n    print(f\"VAL ACC : {acc_epoch_history[1][-1]}  VAL LOSS : {loss_epoch_history[1][-1]}\")\n    print(f\"VAL PRECISION: {precision}  RECALL: {recall}  F1: {f1}\")\n    print(\"====================================================\")\n    \n    torch.save({\n            'epoch': e,\n            'model_state_dict': convnext_model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss_epoch_history[0][-1],\n            'acc' : acc_epoch_history[0][-1]\n            }, f'{current_dateTime}-{filter_method}-{transform_method}-{loss_epoch_history[1][-1]}.pt')\n\nconvnext_model.eval()\n\nwith torch.no_grad():\n    true_positives = 0\n    false_positives = 0\n    false_negatives = 0\n    for i, (data, labels, target) in enumerate(test_loader):\n        data, labels, target = data.to(device), labels.to(device), target.to(device)\n        output = convnext_model(data)\n        labels = labels.float()\n        test_loss = F.kl_div(F.log_softmax(output, dim=1), labels, reduction='batchmean')\n\n        predicted_labels = output.argmax(dim=1)\n        true_positives += ((predicted_labels == target) & (predicted_labels == 1)).sum().item()\n        false_positives += ((predicted_labels == 1) & (target == 0)).sum().item()\n        false_negatives += ((predicted_labels == 0) & (target == 1)).sum().item()\n        \n        test_accuracy = (output.argmax(dim=1) == target).float().mean()\n\n    precision = precision_score(target.cpu(), predicted_labels.cpu(), average='weighted', zero_division=1)\n    recall = recall_score(target.cpu(), predicted_labels.cpu(), average='weighted', zero_division=1)\n    f1 = f1_score(target.cpu(), predicted_labels.cpu(), average='weighted', zero_division=1)\n\nprint(\"====================================================\")\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision: {precision}, Recall: {recall}, F1: {f1}\")\nprint(\"====================================================\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T01:46:04.867723Z","iopub.execute_input":"2024-04-26T01:46:04.868668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plots of Accuracy and Loss vs Epochs","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ntrain_acc_np = np.array([item.cpu() for item in acc_epoch_history[0]])\nval_acc_np = np.array([item.cpu() for item in acc_epoch_history[1]])\n\n# Plot accuracy history\nplt.figure(figsize=(10, 5))\nplt.plot(train_acc_np, label='Train Accuracy')\nplt.plot(val_acc_np, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy vs. Epoch')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot loss history\nplt.figure(figsize=(10, 5))\nplt.plot(loss_epoch_history[0], label='Train Loss')\nplt.plot(loss_epoch_history[1], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss vs. Epoch')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}