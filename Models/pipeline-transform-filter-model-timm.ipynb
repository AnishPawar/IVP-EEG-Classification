{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8176205,"sourceType":"datasetVersion","datasetId":4839831},{"sourceId":8176439,"sourceType":"datasetVersion","datasetId":4840001},{"sourceId":8196662,"sourceType":"datasetVersion","datasetId":4855160}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nimport timm\nimport gc\n\nfrom fastai.vision.all import *\nfrom fastcore.parallel import *","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-04-24T12:55:06.936303Z","iopub.execute_input":"2024-04-24T12:55:06.937219Z","iopub.status.idle":"2024-04-24T12:55:15.961261Z","shell.execute_reply.started":"2024-04-24T12:55:06.937184Z","shell.execute_reply":"2024-04-24T12:55:15.960341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom scipy.signal import butter, filtfilt\nimport librosa\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom tqdm import tqdm,trange,tqdm_notebook\nfrom multiprocessing import Pool\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:55:15.962933Z","iopub.execute_input":"2024-04-24T12:55:15.963346Z","iopub.status.idle":"2024-04-24T12:55:16.016233Z","shell.execute_reply.started":"2024-04-24T12:55:15.963321Z","shell.execute_reply":"2024-04-24T12:55:16.015381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create `DataLoaders`","metadata":{}},{"cell_type":"markdown","source":"Instead of processing the parquet files, I'm now using images directly which I have saved here after preprocessing and converting into the spectrogram. ","metadata":{}},{"cell_type":"code","source":"class Upload_Dataset(Dataset):\n    def __init__(self, csv_path, transform=None, root=\"..\"):\n        self.metadata = pd.read_csv(csv_path)\n        self.root = root\n        self.transform = transform\n        self.label_map = {'Seizure': 0, 'GPD': 1, 'LRDA': 2, 'Other': 3, 'GRDA': 4, 'LPD': 5}\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, idx):\n        subSet = self.metadata.iloc[idx]\n        eeg_id = subSet['eeg_id']\n        offset_seconds = int(subSet['eeg_label_offset_seconds'])\n        image_name = f\"{eeg_id}-{offset_seconds}.png\"\n        image_path = os.path.join(self.root, image_name)\n        image = Image.open(image_path)\n\n        image = self.transform(image)\n\n        # Extract labels\n        labels = np.array([subSet['seizure_vote'], subSet['lpd_vote'], subSet['gpd_vote'],\n                           subSet['lrda_vote'], subSet['grda_vote'], subSet['other_vote']], dtype=float)\n        total_labels = np.sum(labels)\n        labels /= total_labels\n\n        # Extract consensus\n        consensus = self.label_map[subSet['expert_consensus']]\n\n        return image, labels, consensus","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:55:16.017949Z","iopub.execute_input":"2024-04-24T12:55:16.018227Z","iopub.status.idle":"2024-04-24T12:55:16.028015Z","shell.execute_reply.started":"2024-04-24T12:55:16.018203Z","shell.execute_reply":"2024-04-24T12:55:16.026958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\nbatch_size = 128\n\ntrain_path = '/kaggle/input/hms-datasplit/train_mine.csv'\ntest_path = '/kaggle/input/hms-datasplit/test_mine.csv'\nval_path = '/kaggle/input/hms-datasplit/val_mine.csv'\nroot = '/kaggle/input/hms-ivp-pre-processed'\nfilter_method = 'haar'  # Here we can change it to LPF10, LPF20 and db8 also\ntransform_method = 'CWT'  # Here we can change the tranform method to Superlet(SL) and MEL also.\npre_spec = os.path.join(root, f\"/kaggle/input/hms-ivp-pre-processed/hms-harmful-brain-activity-classification-{filter_method}-{transform_method}/hms-harmful-brain-activity-classification-{filter_method}-{transform_method}\")\n\ntrain_dataset = Upload_Dataset(csv_path=train_path, transform=transform,root=os.path.join(pre_spec,f\"train\"))\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n\n\ntest_dataset = Upload_Dataset(csv_path=test_path, transform=transform,root=os.path.join(pre_spec,f\"test\"))\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n\n\nval_dataset = Upload_Dataset(csv_path=val_path, transform=transform,root=os.path.join(pre_spec,f\"val\"))\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:55:16.031090Z","iopub.execute_input":"2024-04-24T12:55:16.031444Z","iopub.status.idle":"2024-04-24T12:55:16.477202Z","shell.execute_reply.started":"2024-04-24T12:55:16.031418Z","shell.execute_reply":"2024-04-24T12:55:16.476203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Models","metadata":{}},{"cell_type":"markdown","source":"Here we have tried out 4 different Models which we have loaded using timm such as ConvNextv2_atto, EfficientNet, Swinv2_tiny and MaxViT. Similarly try out rest of the models also with different methods and variantions in parameters.","metadata":{}},{"cell_type":"code","source":"class EfficientNet(nn.Module):\n    def __init__(self, n_classes, num_input_channels=1, pretrained=False):\n\n        super(EfficientNet, self).__init__()\n\n        self.model = timm.create_model(\"tf_efficientnetv2_s.in21k\", pretrained=False, in_chans=num_input_channels, num_classes=n_classes)\n        if pretrained:\n            self.model.load_state_dict(torch.load(\"../input/...\"))\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nepoch = 15\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n    EfficientNet_model = nn.DataParallel(EfficientNet(6, 1, False)).to(device)\nelse:\n    EfficientNet_model = EfficientNet(6, 1, False).to(device)\n\nloss_history = [[], []]\naccuracy_history = [[], []]\nacc_epoch_history = [[],[]]\nloss_epoch_history = [[],[]]\n\noptimizer = torch.optim.Adam(EfficientNet_model.parameters(), lr=2e-04)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:55:16.478487Z","iopub.execute_input":"2024-04-24T12:55:16.478801Z","iopub.status.idle":"2024-04-24T12:55:17.197235Z","shell.execute_reply.started":"2024-04-24T12:55:16.478775Z","shell.execute_reply":"2024-04-24T12:55:17.196258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvNext(nn.Module):\n    def __init__(self, n_classes, num_input_channels=1, pretrained=False):\n\n        super(ConvNext, self).__init__()\n\n        self.model = timm.create_model(\"convnextv2_atto\", pretrained=False, in_chans=num_input_channels, num_classes=n_classes)\n        if pretrained:\n            self.model.load_state_dict(torch.load(\"../input/...\"))\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nepoch = 15\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n    convnext_model = nn.DataParallel(ConvNext(6, 1, False)).to(device)\nelse:\n    convnext_model = ConvNext(6, 1, False).to(device)\n\nloss_history = [[], []]\naccuracy_history = [[], []]\nacc_epoch_history = [[],[]]\nloss_epoch_history = [[],[]]\n\noptimizer = torch.optim.Adam(convnext_model.parameters(), lr=2e-04)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Swin_Tiny(nn.Module):\n    def __init__(self, n_classes, num_input_channels=1, pretrained=False):\n\n        super(Swin_Tiny, self).__init__()\n\n        self.model = timm.create_model(\"swinv2_tiny_window16_256\", pretrained=False, in_chans=num_input_channels, num_classes=n_classes)\n        if pretrained:\n            self.model.load_state_dict(torch.load(\"../input/...\"))\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nepoch = 15\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n    Swin_Tiny_model = nn.DataParallel(Swin_Tiny(6, 1, False)).to(device)\nelse:\n    Swin_Tiny_model = Swin_Tiny(6, 1, False).to(device)\n\nloss_history = [[], []]\naccuracy_history = [[], []]\nacc_epoch_history = [[],[]]\nloss_epoch_history = [[],[]]\n\noptimizer = torch.optim.Adam(Swin_Tiny_model.parameters(), lr=2e-04)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MaxViT_tiny(nn.Module):\n    def __init__(self, n_classes, num_input_channels=1, pretrained=False):\n\n        super(MaxViT_tiny, self).__init__()\n\n        self.model = timm.create_model(\"tf_efficientnetv2_s.in21k\", pretrained=False, in_chans=num_input_channels, num_classes=n_classes)\n        if pretrained:\n            self.model.load_state_dict(torch.load(\"../input/...\"))\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nepoch = 15\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n    MaxViT_tiny_model = nn.DataParallel(MaxViT_tiny(6, 1, False)).to(device)\nelse:\n    MaxViT_tiny_model = MaxViT_tiny(6, 1, False).to(device)\n\nloss_history = [[], []]\naccuracy_history = [[], []]\nacc_epoch_history = [[],[]]\nloss_epoch_history = [[],[]]\n\noptimizer = torch.optim.Adam(MaxViT_tiny_model.parameters(), lr=2e-04)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training and Evaluation","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\ncurrent_dateTime = datetime.now()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:55:17.198545Z","iopub.execute_input":"2024-04-24T12:55:17.199113Z","iopub.status.idle":"2024-04-24T12:55:17.203760Z","shell.execute_reply.started":"2024-04-24T12:55:17.199079Z","shell.execute_reply":"2024-04-24T12:55:17.202655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\nprecision_history = [[], []]\nrecall_history = [[], []]\nf1_history = [[], []]\n\nfor e in trange(epoch):\n    convnext_model.train()\n    print(f\"====================== EPOCH {e+1} ======================\")\n    print(\"Training.....\")\n    for i, (data, labels, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        data, labels, target = data.to(device), labels.to(device), target.to(device)\n        output = convnext_model(data.float())\n        labels = labels.float()\n        loss = F.kl_div(F.log_softmax(output, dim=1), labels, reduction='batchmean')\n        \n        loss.backward()\n        \n        nn.utils.clip_grad_norm_(convnext_model.parameters(), 3)\n\n        loss_history[0].append(loss.item())\n        \n        accuracy = (output.argmax(dim=1) == target).float().mean()\n        \n        accuracy_history[0].append(accuracy)\n        \n        optimizer.step()\n        \n        if(i%50 == 0):\n            print(f\"MINIBATCH {i+1}/{len(train_loader)} TRAIN LOSS : {loss_history[0][-1]}\")\n    \n    print(\"Validation.....\")\n    convnext_model.eval()\n    \n    with torch.no_grad():\n        true_positives = 0\n        false_positives = 0\n        false_negatives = 0\n        for i, (data, labels, target) in enumerate(val_loader):\n            data, labels, target = data.to(device), labels.to(device), target.to(device)\n            output = convnext_model(data)\n            labels = labels.float()\n            loss = F.kl_div(F.log_softmax(output, dim=1), labels, reduction='batchmean')\n            \n            predicted_labels = output.argmax(dim=1)\n            true_positives += ((predicted_labels == target) & (predicted_labels == 1)).sum().item()\n            false_positives += ((predicted_labels == 1) & (target == 0)).sum().item()\n            false_negatives += ((predicted_labels == 0) & (target == 1)).sum().item()\n\n            accuracy = (output.argmax(dim=1) == target).float().mean()\n            loss_history[1].append(loss.item())\n            accuracy_history[1].append(accuracy)\n        \n        precision = precision_score(target.cpu(), predicted_labels.cpu(), average='weighted')\n        recall = recall_score(target.cpu(), predicted_labels.cpu(), average='weighted')\n        f1 = f1_score(target.cpu(), predicted_labels.cpu(), average='weighted')\n\n        precision_history[1].append(precision)\n        recall_history[1].append(recall)\n        f1_history[1].append(f1)\n        \n    acc_epoch_history[0].append(sum(accuracy_history[0][-1:-len(train_loader):-1])/len(train_loader))\n    acc_epoch_history[1].append(sum(accuracy_history[1][-1:-len(val_loader):-1])/len(val_loader))\n    \n    loss_epoch_history[0].append(sum(loss_history[0][-1:-len(train_loader):-1])/len(train_loader))\n    loss_epoch_history[1].append(sum(loss_history[1][-1:-len(val_loader):-1])/len(val_loader))\n    \n    print(\"====================================================\")\n    print(f\"TRAIN ACC : {acc_epoch_history[0][-1]}  TRAIN LOSS : {loss_epoch_history[0][-1]}\")\n    print(f\"VAL ACC : {acc_epoch_history[1][-1]}  VAL LOSS : {loss_epoch_history[1][-1]}\")\n    print(f\"VAL PRECISION: {precision}  RECALL: {recall}  F1: {f1}\")\n    print(\"====================================================\")\n    \n    torch.save({\n            'epoch': e,\n            'model_state_dict': convnext_model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss_epoch_history[0][-1],\n            'acc' : acc_epoch_history[0][-1]\n            }, f'{current_dateTime}-{filter_method}-{transform_method}-{loss_epoch_history[1][-1]}.pt')\n\nconvnext_model.eval()\n\nwith torch.no_grad():\n    true_positives = 0\n    false_positives = 0\n    false_negatives = 0\n    for i, (data, labels, target) in enumerate(test_loader):\n        data, labels, target = data.to(device), labels.to(device), target.to(device)\n        output = convnext_model(data)\n        labels = labels.float()\n        test_loss = F.kl_div(F.log_softmax(output, dim=1), labels, reduction='batchmean')\n\n        predicted_labels = output.argmax(dim=1)\n        true_positives += ((predicted_labels == target) & (predicted_labels == 1)).sum().item()\n        false_positives += ((predicted_labels == 1) & (target == 0)).sum().item()\n        false_negatives += ((predicted_labels == 0) & (target == 1)).sum().item()\n        \n        test_accuracy = (output.argmax(dim=1) == target).float().mean()\n\n    precision = true_positives / (true_positives + false_positives)\n    recall = true_positives / (true_positives + false_negatives)\n    f1 = 2 * (precision * recall) / (precision + recall)\n\nprint(\"====================================================\")\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision: {precision}, Recall: {recall}, F1: {f1}\")\nprint(\"====================================================\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T12:55:17.205657Z","iopub.execute_input":"2024-04-24T12:55:17.206055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plots of Accuracy and Loss vs Epochs","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ntrain_acc_np = np.array([item.cpu() for item in acc_epoch_history[0]])\nval_acc_np = np.array([item.cpu() for item in acc_epoch_history[1]])\n\n# Plot accuracy history\nplt.figure(figsize=(10, 5))\nplt.plot(train_acc_np, label='Train Accuracy')\nplt.plot(val_acc_np, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy vs. Epoch')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot loss history\nplt.figure(figsize=(10, 5))\nplt.plot(loss_epoch_history[0], label='Train Loss')\nplt.plot(loss_epoch_history[1], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss vs. Epoch')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}